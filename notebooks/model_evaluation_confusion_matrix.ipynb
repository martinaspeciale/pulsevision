{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation â€” Confusion Matrix and Classification Report\n",
    "\n",
    "This notebook was used to generate the confusion matrix and classification report reported in the thesis document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23835,
     "status": "ok",
     "timestamp": 1686380092355,
     "user": {
      "displayName": "MARTINA SPECIALE",
      "userId": "00671972012281337451"
     },
     "user_tz": -120
    },
    "id": "2_d0hoJkgcmY",
    "outputId": "22a0f295-cfb9-43e9-f224-0f2578876a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFOOzTk-jlGD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMaJ3GhDlEIC"
   },
   "source": [
    "# **F1 Score, Recall & Precision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGPqiYm1NN8g"
   },
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmcOGhN9X73b"
   },
   "source": [
    "# **Confution Matrix and Classification Report**\n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "The performance of the trained model is evaluated using:\n",
    "\n",
    "- **Confusion Matrix:** provides a detailed view of the correct and incorrect predictions for each class.\n",
    "- **Classification Report:** precision, recall, and F1 Score for each class.\n",
    "\n",
    "Given the imbalanced nature of the dataset (more NORMAL than HIGH samples), particular attention is given to the F1 Score as the main evaluation metric.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JidcgvZRX7Ea"
   },
   "outputs": [],
   "source": [
    "DATADIR = '/content/drive/MyDrive/TesiPressione/dataset/classes/Polso/_sys/validation'\n",
    "CATEGORIES = ['high', 'normal']\n",
    "\n",
    "testing_data = []\n",
    "def create_testing_data():\n",
    "  for category in CATEGORIES :\n",
    "    path = os.path.join(DATADIR, category)\n",
    "    class_num = CATEGORIES.index(category)\n",
    "    for img in os.listdir(path) :\n",
    "      img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "      testing_data.append([img_array, class_num])\n",
    "\n",
    "create_testing_data()\n",
    "\n",
    "test_set = [] #labels\n",
    "\n",
    "for features, label in testing_data:\n",
    "  test_set.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5iYypN02k4EP"
   },
   "outputs": [],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "predictions = model.predict(validation_dataset).round()\n",
    "#print('\\nConfusion Matrix\\n')\n",
    "#print(sklearn.metrics.confusion_matrix(Y, predictions))\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(Y, predictions))\n",
    "\n",
    "x = sklearn.metrics.confusion_matrix(Y, predictions)\n",
    "matrix = pandas.DataFrame(x, columns=['pred_high', 'pred_normal'], index=['HIGH', 'NORMAL'])\n",
    "print('\\nConfusion Matrix\\n')\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dy54RCCHyxaB"
   },
   "outputs": [],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "predictions = model.predict(validation_dataset).round()\n",
    "x = confusion_matrix(Y, predictions)\n",
    "\n",
    "matrix = pd.DataFrame(x, columns=['pred_high', 'pred_normal'], index=['HIGH', 'NORMAL'])\n",
    "print('\\nConfusion Matrix\\n')\n",
    "print(matrix)\n",
    "\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(Y, predictions))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPXlCKiOPVyQw4KQD+u1mpI",
   "gpuType": "T4",
   "mount_file_id": "1y18Msw89P7x-2Zp2o4SPpWZJvRcONhwv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
